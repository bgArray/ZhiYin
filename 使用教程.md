# 🎵 知音 - 使用教程

本文档提供了知音AI音频听觉功能集成软件的详细使用指南，帮助您快速上手并充分利用其强大的音频处理能力。

## 📑 目录

- [🎯 项目简介](#-项目简介)
- [🔧 安装配置](#-安装配置)
- [🚀 快速上手](#-快速上手)
- [🎼 功能模块使用指南](#-功能模块使用指南)
  - [音频分类器](#音频分类器)
  - [音源分离器](#音源分离器)
  - [实时录音](#实时录音)
  - [AI分析](#ai分析)
- [📁 常见操作示例](#-常见操作示例)
- [🎛️ 参数调整建议](#-参数调整建议)
- [📞 故障排除](#-故障排除)
- [💡 最佳实践](#-最佳实践)

## 🎯 项目简介

**知音**是一款集成多种AI音频处理功能的软件，专为音频爱好者、音乐制作人和声乐学习者设计。它提供了音频分类、音源分离、实时录音和AI分析等多种工具，让音频处理变得简单而强大。

### ✨ 核心功能

- **音频分类**: 使用深度学习模型识别8种声乐标签
- **音源分离**: 基于Demucs引擎的多轨道分离
- **实时录音**: 实时进行音频录制和分类
- **AI分析**: 集成Whisper语音识别和歌词对齐

## 🔧 安装配置

### 📋 系统要求

| 组件 | 最低要求 | 推荐配置 |
|------|---------|---------|
| 操作系统 | Windows 10/11 | Windows 11 |
| Python | 3.8+ | 3.9+ |
| 内存 | 4GB | 8GB+ |
| 存储空间 | 5GB | 10GB+ |
| GPU (可选) | NVIDIA GTX 1060+ | NVIDIA RTX 2060+ |
| CUDA (可选) | 11.0+ | 11.7+ |

### 💻 安装步骤

#### 1. 克隆仓库

```bash
git clone https://github.com/yourusername/ZhiYin.git
cd ZhiYin
```

#### 2. 创建虚拟环境

```bash
# Windows
python -m venv zhiyin_env
zhiyin_env\Scripts\activate

# Linux/Mac
python3 -m venv zhiyin_env
source zhiyin_env/bin/activate
```

#### 3. 安装依赖

```bash
# 首先安装PyTorch (根据CUDA版本选择)
# 有GPU的用户
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu117

# 无GPU的用户
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cpu

# 安装其他依赖
pip install -r requirements.txt
```

#### 4. 验证安装

```bash
# 检查Python版本
python --version

# 检查PyTorch安装
python -c "import torch; print(f'PyTorch: {torch.__version__}'); print(f'CUDA: {torch.cuda.is_available()}')"

# 检查关键依赖
python -c "import librosa, soundfile, PySide6; print('依赖安装成功')"
```

### 📁 目录结构

安装完成后，项目目录结构如下：

```
ZhiYin/
├── best_new_models/    # 预训练模型
├── config/             # 配置文件
├── core/               # 核心模块
├── features/           # 功能模块
├── resources/          # 资源文件
├── ui/                 # 用户界面
├── utils/              # 工具函数
├── README.md           # 项目说明
├── 使用教程.md          # 本教程
├── requirements.txt    # 依赖列表
└── main.py             # 主程序入口
```

## 🚀 快速上手

### 🔄 启动程序

在安装完成并激活虚拟环境后，运行以下命令启动程序：

```bash
python main.py
```

程序启动后，您将看到主界面，左侧是功能导航栏，右侧是欢迎信息。

### 🎯 首次使用步骤

1. **加载模型**: 首次启动时，系统会自动尝试加载默认模型
2. **选择功能**: 从左侧导航栏选择您需要的功能模块
3. **导入音频**: 根据功能模块的要求，导入或录制音频
4. **开始处理**: 点击相应按钮开始音频处理
5. **查看结果**: 处理完成后，查看分析结果和可视化图表

## 🎼 功能模块使用指南

### 音频分类器

音频分类器是知音的核心功能，用于识别音频中的声乐技术标签。

#### 📋 操作步骤

1. **打开音频文件**: 点击工具栏中的"打开音频文件"按钮，选择要分析的音频文件
2. **等待处理**: 系统会自动加载模型并进行分析，显示进度对话框
3. **查看结果**: 分析完成后，分类结果会以图表形式显示，包括各标签的置信度曲线
4. **调整阈值**: 使用阈值滑块过滤低置信度的结果
5. **选择标签**: 在右侧面板中勾选或取消勾选要显示的标签
6. **播放音频**: 使用播放控制按钮预览音频，观察波形和分类结果的对应关系
7. **保存结果**: 分析完成后，系统会自动保存对齐结果到JSON文件

#### ⚙️ 参数说明

- **阈值**: 控制分类结果的敏感度，值越高，结果越严格
- **模型选择**: 可选择标准模型或增强模型
- **发生位置增强**: 可选使用M6LSTM_CNN模型增强发声位置判断精度

### 音源分离器

音源分离器使用Demucs引擎将音频分离为人声、贝斯、鼓点和其他乐器四个轨道。

#### 📋 操作步骤

1. **打开音频文件**: 点击"打开音频文件"按钮，选择要分离的音频文件
2. **选择模型**: 从下拉菜单中选择适合的分离模型（如mdx_extra_q、htdemucs等）
3. **设置输出路径**: 选择分离结果的保存目录
4. **开始分离**: 点击"开始分离"按钮，系统会显示处理进度
5. **查看结果**: 分离完成后，系统会在指定目录生成四个分离后的音频文件
6. **预览结果**: 可点击各轨道的播放按钮预览分离效果

#### ⚙️ 参数说明

- **分离模型**: 不同模型的分离效果和速度不同，根据需要选择
- **输出格式**: 可选择WAV、MP3等格式
- **分离质量**: 可调整分离的质量和速度平衡

### 实时录音

实时录音功能允许您实时录制音频并进行分类分析。

#### 📋 操作步骤

1. **选择设备**: 从设备下拉菜单中选择麦克风设备
2. **设置参数**: 调整采样率、通道数等录音参数
3. **开始录音**: 点击"开始录音"按钮开始录制
4. **实时观察**: 录制过程中，系统会实时显示音频波形和分类结果
5. **停止录音**: 点击"停止录音"按钮结束录制
6. **保存文件**: 选择保存路径，将录制的音频保存为文件

#### ⚙️ 参数说明

- **采样率**: 推荐使用44100Hz或48000Hz
- **通道数**: 通常使用单声道(1)或立体声(2)
- **缓冲区大小**: 影响录音延迟，值越小延迟越低，但可能增加CPU占用

### AI分析

AI分析模块集成了Whisper语音识别和歌词对齐功能。

#### 📋 操作步骤

1. **处理音频**: 首先在音频分类器中处理音频文件
2. **自动识别**: 处理完成后，系统会自动开始歌词识别
3. **查看歌词**: 识别完成后，歌词会显示在歌词识别区域
4. **对齐结果**: 系统会自动将歌词与音频时间轴对齐
5. **保存结果**: 对齐结果会自动保存为JSON文件

#### ⚙️ 参数说明

- **语言选择**: 可指定音频的语言，提高识别准确率
- **模型大小**: Whisper模型大小影响识别准确率和速度
- **咬字信息**: 可选择是否保留咬字信息

## 📁 常见操作示例

### 示例1: 分析歌曲中的声乐技术

**目标**: 分析一首歌曲中歌手使用的声乐技术

**步骤**:
1. 打开音频分类器模块
2. 导入歌曲文件（建议使用WAV格式）
3. 等待系统分析完成
4. 调整阈值到0.6，过滤低置信度结果
5. 观察图表，识别歌曲中不同部分使用的声乐技术
6. 播放音频，结合波形和分类结果理解声乐技术的应用

**预期结果**: 获得歌曲中各部分的声乐技术标签，如 chorus部分使用了混声，verse部分使用了真声等。

### 示例2: 分离歌曲的人声和伴奏

**目标**: 将一首歌曲分离为人声和伴奏，用于翻唱或 remix

**步骤**:
1. 打开音源分离器模块
2. 导入歌曲文件
3. 选择"mdx_extra_q"模型（平衡分离质量和速度）
4. 设置输出路径
5. 点击"开始分离"
6. 分离完成后，查看生成的四个音频文件
7. 使用人声文件进行翻唱，或使用伴奏进行 remix

**预期结果**: 获得清晰的人声轨道和伴奏轨道，可用于后续的音乐制作。

### 示例3: 实时分析自己的演唱

**目标**: 实时分析自己的演唱，了解使用的声乐技术

**步骤**:
1. 打开实时录音模块
2. 选择正确的麦克风设备
3. 设置采样率为44100Hz，通道数为1
4. 点击"开始录音"
5. 开始演唱一段歌曲
6. 观察实时显示的分类结果
7. 点击"停止录音"，保存录制的音频
8. 可进一步在音频分类器中分析保存的音频

**预期结果**: 实时了解自己演唱时使用的声乐技术，发现需要改进的地方。

## 🎛️ 参数调整建议

### 音频分类参数

| 参数 | 推荐值 | 适用场景 | 调整建议 |
|------|-------|---------|--------|
| 阈值 | 0.5-0.7 | 一般分析 | 标准歌曲分析使用0.6 |
| 模型选择 | 标准模型 | 快速分析 | 对结果要求高时使用增强模型 |
| 发生位置增强 | 开启 | 专业分析 | 分析发声位置时开启 |

### 音源分离参数

| 参数 | 推荐值 | 适用场景 | 调整建议 |
|------|-------|---------|--------|
| 分离模型 | mdx_extra_q | 一般分离 | 时间充裕时使用htdemucs |
| 输出格式 | WAV | 高质量需求 | 存储空间有限时使用MP3 |
| 分离质量 | 中等 | 平衡需求 | 对质量要求高时选择高质量 |

### 实时录音参数

| 参数 | 推荐值 | 适用场景 | 调整建议 |
|------|-------|---------|--------|
| 采样率 | 44100Hz | 一般录音 | 专业录音使用48000Hz |
| 通道数 | 1 | 单人录音 | 多人录音使用2 |
| 缓冲区大小 | 1024 | 一般使用 | 低延迟需求时使用512 |

## 📞 故障排除

### 🐛 常见问题及解决方案

#### 1. 程序启动失败

**症状**: 运行`python main.py`后程序无法启动

**可能原因**:
- 依赖安装不完整
- PySide6版本不兼容
- Python版本过低

**解决方案**:
- 重新安装依赖: `pip install -r requirements.txt`
- 确保Python版本≥3.8
- 检查PySide6版本: `pip show PySide6`

#### 2. 模型加载失败

**症状**: 启动程序后显示"模型加载失败"

**可能原因**:
- 模型文件不存在
- 模型文件路径错误
- CUDA版本不兼容

**解决方案**:
- 确保`best_new_models`目录中的模型文件完整
- 检查配置文件中的模型路径设置
- 如果使用GPU，确保CUDA版本与PyTorch兼容

#### 3. 音频处理失败

**症状**: 导入音频后处理失败，显示错误信息

**可能原因**:
- 音频文件格式不支持
- 音频文件损坏
- 内存不足

**解决方案**:
- 使用WAV格式的音频文件
- 确保音频文件完整无损
- 处理较短的音频片段（如30秒以内）
- 关闭其他占用内存的应用

#### 4. 歌词识别失败

**症状**: 音频处理完成后歌词识别失败

**可能原因**:
- 音频质量差
- 音频中无人声
- 语言不被支持

**解决方案**:
- 使用清晰的音频文件
- 确保音频中有人声部分
- 在设置中指定正确的语言

#### 5. 实时录音无声音

**症状**: 启动实时录音后看不到波形或听不到声音

**可能原因**:
- 麦克风设备选择错误
- 麦克风权限未授予
- 音频设置错误

**解决方案**:
- 选择正确的麦克风设备
- 检查系统麦克风权限设置
- 调整录音音量和增益设置

### 📊 性能问题排查

#### 1. 处理速度慢

**可能原因**:
- 使用CPU而非GPU
- 模型选择不当
- 系统资源不足

**解决方案**:
- 确保PyTorch能够使用GPU: `torch.cuda.is_available()`
- 选择适合的模型，平衡质量和速度
- 关闭其他占用系统资源的应用

#### 2. 内存占用过高

**可能原因**:
- 音频文件过长
- 批处理大小设置过大
- 同时运行多个功能模块

**解决方案**:
- 处理较短的音频片段
- 减少批处理大小
- 一次只运行一个功能模块
- 定期清理系统内存

## 💡 最佳实践

### 🎯 提高分析准确率

1. **使用高质量音频**: WAV格式，44.1kHz采样率，16位深度
2. **控制音频长度**: 单段分析建议30秒以内，最长不超过3分钟
3. **选择合适模型**: 对结果要求高时使用增强模型
4. **调整阈值**: 根据实际情况调整阈值，平衡精度和召回率
5. **结合上下文**: 分析结果时结合音频内容和演唱风格进行理解

### 📁 音频文件管理

1. **统一命名规范**: 使用清晰的文件名，包含歌曲名和版本信息
2. **分类存储**: 按功能和用途分类存储音频文件
3. **备份重要文件**: 定期备份分析结果和处理后的音频
4. **清理临时文件**: 音源分离和处理过程中会产生临时文件，定期清理

### 🔄 工作流程建议

1. **音频分类工作流**:
   - 导入音频 → 分析 → 调整阈值 → 选择标签 → 查看结果 → 保存

2. **音源分离工作流**:
   - 导入音频 → 选择模型 → 设置参数 → 开始分离 → 预览结果 → 保存

3. **实时录音工作流**:
   - 选择设备 → 设置参数 → 开始录音 → 实时观察 → 停止录音 → 保存 → 分析

4. **AI分析工作流**:
   - 处理音频 → 自动识别歌词 → 查看对齐结果 → 保存JSON文件

### 🎓 学习资源

- **官方文档**: 本文档和项目README.md
- **视频教程**: 后续将提供详细的视频教程
- **社区论坛**: 加入我们的社区，分享经验和问题
- **示例项目**: 查看项目中的示例音频和分析结果

## 📝 结语

知音是一款功能强大的AI音频处理软件，通过本教程的指导，您应该能够快速上手并充分利用其各项功能。随着您的使用经验增加，您会发现更多创意用法和技巧。

如果您在使用过程中遇到任何问题，或有任何建议和反馈，欢迎联系我们的开发团队。

祝您使用愉快！🎵

---

**版本**: v1.4.0
**更新日期**: 2026-02-09
**作者**: bgArray
